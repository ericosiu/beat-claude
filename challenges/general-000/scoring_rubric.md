# Scoring Rubric: General 000

## Overview

This challenge has a different structure than role-specific challenges. Applicants submit three parts: the role they want, proof of exceptional ability, and their AI edge. Scoring reflects this.

## Scoring Criteria (100 points)

### Evidence of Exceptional Ability — 40 points

The core question: **Can this person prove they've done exceptional work?**

| Score | Criteria |
|-------|----------|
| 32-40 | 2-3 examples with verifiable numbers, real artifacts (links, screenshots, repos), and clear cause-and-effect. Results are genuinely impressive for their field. |
| 20-31 | Solid examples with some evidence, but missing verification or specificity in places. Results are good but not clearly exceptional. |
| 8-19 | Claims without strong evidence. Responsibilities described but outcomes unclear. |
| 0-7 | Generic self-description. No numbers, no artifacts, no verifiable claims. |

### AI Fluency & Vision — 25 points

Do they actually use AI at a high level, or just talk about it?

| Score | Criteria |
|-------|----------|
| 20-25 | Specific AI stack with concrete workflows described. Best AI win is genuinely impressive with clear outcome. Future predictions are specific, non-obvious, and defensible. |
| 12-19 | Uses AI tools but descriptions are surface-level. Predictions are reasonable but generic. |
| 5-11 | Mentions AI but clearly isn't deeply integrated into their work. Predictions are "AI will change everything" tier. |
| 0-4 | Little to no evidence of working with AI. |

### Self-Awareness & Fit — 15 points

Do they know what they're great at and where they'd add value?

| Score | Criteria |
|-------|----------|
| 12-15 | Clear, specific description of the role they want. 90-day plan shows they've researched Single Grain. Honest about strengths and gaps. |
| 7-11 | Reasonable role description but generic. Could apply to any company. |
| 3-6 | Vague about what they want to do. No evidence of research into SG. |
| 0-2 | "I'm open to anything" or clearly misaligned with what SG does. |

### Communication Quality — 10 points

| Score | Criteria |
|-------|----------|
| 8-10 | Tight, scannable, no fluff. Every sentence earns its place. Professional but has personality. |
| 5-7 | Readable but some filler or poor organization. |
| 2-4 | Wordy, buried lead, hard to scan. |
| 0-1 | Confusing, unprofessional, or clearly unedited. |

### Non-Obvious Insight — 10 points

| Score | Criteria |
|-------|----------|
| 8-10 | Shows us something we haven't seen. A pattern, a prediction, a connection that makes us think differently. |
| 5-7 | Some fresh thinking but mostly conventional. |
| 2-4 | Entirely conventional. Nothing surprising. |
| 0-1 | Cookie-cutter thinking. |

## Bonus Criterion

### The Dinner Test (Pass/Fail)

After scoring, the reviewer answers:

> "Would I want to spend 2 hours at dinner listening to this person talk?"

**If Pass:** Advance to conversation regardless of score (as long as score is above 50).

**If Fail:** Standard scoring rules apply — must beat Claude's score to advance.

## Red Flags (Auto-Deduct)

| Red Flag | Deduction |
|----------|-----------|
| No verifiable evidence of any claim | -15 |
| Submission reads like raw AI output | -15 |
| "Exceptional ability" examples are just normal job responsibilities | -10 |
| No personal experience with AI tools | -10 |
| Clearly didn't research Single Grain | -5 |

## What Beats Claude on This Challenge

Claude's baseline will be structured and competent but inherently generic — it can't provide real work samples, real numbers from real projects, or genuine personal AI workflow details.

Any applicant who provides **verifiable proof of genuinely exceptional results** automatically differentiates from Claude's baseline.
